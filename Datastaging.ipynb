{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a2652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "import pyspark.sql.types\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e4bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filters years from 2005-2020\n",
    "# 2. Unbucketize the columns\n",
    "# 3. Filters chosen countries\n",
    "def filterCountryData(df,countries_chosen):\n",
    "    \n",
    "    # range b/w 2005-2020\n",
    "    years = list(map(lambda x: str(x),list(range(2005,2021,1)))) \n",
    "    \n",
    "    cols =[\"Country Name\",\"Country Code\",\"Indicator Name\",\"Indicator Code\"]+years\n",
    "    country_2005_20 = df.select(cols)\n",
    "    \n",
    "    \n",
    "    # filters countries chosen and fills any missing year values with 0.00\n",
    "    ts = \"2020-04-01\"\n",
    "    countries_chosen_2005_20 = (country_2005_20\n",
    "                                .filter(fn.col(\"Country Name\").isin(countries_chosen))\n",
    "                                .withColumn(\"date\",fn.date_format(fn.lit(ts),\"yyyy-MM-dd\"))\n",
    "                               )\n",
    "    \n",
    "    #unbucketize the data\n",
    "    unpivotStr= list(map(lambda x: \" '{t}',`{t}`\".format(t=x),years))\n",
    "    sep = ','\n",
    "    unpivotExpr = \"stack(\"+str(len(years))+\", \"+sep.join(unpivotStr)+\") as (Year, Value)\"\n",
    "    columns_without_years= set(countries_chosen_2005_20.columns ) - set(years)\n",
    "    \n",
    "    res = countries_chosen_2005_20.select(\n",
    "        \"Country Name\",\n",
    "        \"Country Code\",\n",
    "        \"Indicator Name\",\n",
    "        fn.expr(unpivotExpr),\n",
    "        fn.month(\"date\").alias(\"month\"),\n",
    "        fn.dayofmonth(\"date\").alias(\"day\"),\n",
    "        fn.quarter(\"date\").alias(\"quarter\")            \n",
    "    ).groupBy(\"Country Name\",\"Year\").pivot(\"Indicator Name\").sum(\"Value\")\n",
    "    \n",
    "    #TODO: join the dimensions to make a fact table\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002bfeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Dimension\n",
    "def generate_dates(spark,range_list,interval=60*60*24,dt_col=\"date_time_ref\"): # TODO: attention to sparkSession\n",
    "     \"\"\"\n",
    "     Create a Spark DataFrame with a single column named dt_col and a range of date within a specified interval (start and stop included).\n",
    "     With hourly data, dates end at 23 of stop day\n",
    "\n",
    "     :param spark: SparkSession or sqlContext depending on environment (server vs local)\n",
    "     :param range_list: array of strings formatted as \"2018-01-20\" or \"2018-01-20 00:00:00\"\n",
    "     :param interval: number of seconds (frequency), output from get_freq()\n",
    "     :param dt_col: string with date column name. Date column must be TimestampType\n",
    "\n",
    "     :returns: df from range\n",
    "     \"\"\"\n",
    "     start,stop = range_list\n",
    "     temp_df = spark.createDataFrame([(start, stop)], (\"start\", \"stop\"))\n",
    "     temp_df = temp_df.select([fn.col(c).cast(\"timestamp\") for c in (\"start\", \"stop\")])\n",
    "     temp_df = temp_df.withColumn(\"stop\",fn.date_add(\"stop\",1).cast(\"timestamp\"))\n",
    "     temp_df = temp_df.select([fn.col(c).cast(\"long\") for c in (\"start\", \"stop\")])\n",
    "     start, stop = temp_df.first()\n",
    "     return spark.range(start,stop,interval).select(fn.col(\"id\").cast(\"timestamp\").alias(dt_col))\n",
    "\n",
    "\n",
    "def dateDimension():\n",
    "    time_rng = [\"2005-01-01\",\"2020-12-31\"]\n",
    "    year_df= generate_dates(spark,time_rng)\n",
    "    tmp = (year_df\n",
    "           .withColumn(\"year\",fn.year(\"date_time_ref\"))\n",
    "           .withColumn(\"month\",fn.month(\"date_time_ref\"))\n",
    "           .withColumn(\"day\",fn.dayofmonth(\"date_time_ref\"))\n",
    "           .withColumn(\"quarter\",fn.quarter(\"date_time_ref\"))\n",
    "           .withColumn(\"decade\",\n",
    "                          fn.when(fn.col(\"year\") % 10 >=5,fn.col(\"year\")-fn.col(\"year\")%10+10)\n",
    "                              .otherwise(fn.col(\"year\")- fn.col(\"year\") % 10))\n",
    "           .withColumn(\"year_code\",fn.monotonically_increasing_id())\n",
    "\n",
    "          )\n",
    "    date_dim = (tmp\n",
    "                   .select(tmp.year_code,*set(tmp.columns)-set([\"year_code\"]))\n",
    "               )\n",
    "    \n",
    "    return date_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb726a15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12255/2584504711.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mdateDim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdateDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m df, tmp=naturalDisasterDim(\n\u001b[1;32m     95\u001b[0m     \u001b[0mdateDim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12255/2206534258.py\u001b[0m in \u001b[0;36mdateDimension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdateDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtime_rng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"2005-01-01\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2020-12-31\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0myear_df\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgenerate_dates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_rng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     tmp = (year_df\n\u001b[1;32m     27\u001b[0m            \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"year\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"date_time_ref\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "def naturalDisasterDim(df,filePath,countries_chosen):\n",
    "    \"\"\"\n",
    "        creates natural disaster dimension + look up table\n",
    "    \n",
    "        df - date dataframe\n",
    "        filePath - filePath to natural disaster csv\n",
    "        countries_chosen - list of strings of countries to work on\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = [\"total deaths\",\"Total Damages ('000 US$)\"]\n",
    "    \n",
    "    # reads csv\n",
    "    natural_disaster_df = (spark\n",
    "                       .read\n",
    "                       .format('csv')\n",
    "                           .option(\"inferSchema\",True)\n",
    "                           .option(\"header\",True)\n",
    "                           .load(filePath)\n",
    "                           .fillna(0.00,subset=columns)).dropDuplicates()\n",
    "    \n",
    "\n",
    "    # reconfigures column names + banding\n",
    "    tmp_nd = (natural_disaster_df\n",
    "                  # replaces United States of America -> united states\n",
    "              .withColumn(\"Country\",fn.when(fn.lower(fn.col(\"Country\")).contains(\"united states\"),\"united states\").otherwise(fn.lower(fn.col(\"Country\"))))\n",
    "              .withColumn(\"start_month\",fn.col(\"Start Month\"))\n",
    "                  .withColumn(\"start_year\",fn.col(\"Start Year\"))\n",
    "                  .withColumn(\"start_day\",fn.col(\"Start Day\"))\n",
    "                  .withColumn(\"end_month\",fn.col(\"End Month\"))\n",
    "                  .withColumn(\"end_year\",fn.col(\"End Year\"))\n",
    "                  .withColumn(\"end_day\",fn.col(\"End Day\"))\n",
    "              .withColumn(\"disaster_type\",fn.col(\"Disaster Type\"))\n",
    "              .withColumn(\"disaster_subtype\",fn.col(\"disaster subtype\"))\n",
    "              .withColumn(\"disaster_nestedsubtype\",fn.col(\"disaster subsubtype\"))\n",
    "              .withColumn(\"disaster_subgroup\",fn.col(\"disaster subgroup\"))\n",
    "              .withColumn(\"event_name\",fn.col(\"event name\"))\n",
    "              .withColumn(\"ofda_response\",fn.col(\"ofda response\"))\n",
    "              .fillna(1.0,[\"start_day\",\"start_month\",\"start_year\",\"end_day\",\"end_month\",\"end_year\"])\n",
    "              # TODO figure out what to do about start and end year\n",
    "              .fillna(\"Not Available\",[\"disaster_type\",\"disaster_subtype\",\"disaster_nestedsubtype\",\"disaster_subgroup\",\"event_name\",\"ofda_response\"])\n",
    "              .withColumn(\"ttl_death\",\n",
    "                          # range (low,medium, high)\n",
    "                          fn.when(fn.col(\"total deaths\")>7000,\n",
    "                                  fn.when(fn.col(\"total deaths\")>14000,\"high\").otherwise(\"medium\")).otherwise(\"low\")\n",
    "                         )\n",
    "              .withColumn(\"ttl_damages\",\n",
    "                          # \n",
    "                          fn.when(fn.col(\"Total Damages ('000 US$)\")>1000000,\n",
    "                                  fn.when(fn.col(\"Total Damages ('000 US$)\")>100000000,\"high\").otherwise(\"medium\")).otherwise(\"low\")\n",
    "                         )\n",
    "              \n",
    "                  .drop(\"year\")\n",
    "             )\n",
    "\n",
    "    # join on start year\n",
    "    max_year = df.select(fn.max(\"year\")).limit(1).collect()[0][0]\n",
    "    min_year = df.select(fn.min(\"year\")).limit(1).collect()[0][0]\n",
    "    \n",
    "    nd_j_on_date = tmp_nd.filter(fn.col(\"start_year\")>=min_year).filter(fn.col(\"end_year\")<=max_year)\n",
    "\n",
    "    # filter countries chosen\n",
    "    filtered_byCountry_date = (nd_j_on_date\n",
    "           .filter(fn.col(\"Country\").isin(list(map(lambda x: x.lower(),countries_chosen))))\n",
    "           \n",
    "    )\n",
    "    \n",
    "    # distinct banded rows with key\n",
    "    res = (filtered_byCountry_date  \n",
    "                                  .select([\n",
    "                                           \"disaster_type\",\n",
    "                                           \"disaster_subtype\",\n",
    "                                           \"disaster_nestedsubtype\",\n",
    "                                           \"disaster_subgroup\",\n",
    "                                           \"event_name\",\n",
    "                                           \"ttl_death\",\n",
    "                                           \"ttl_damages\",\n",
    "                                           \"ofda_response\"])                                   \n",
    "                                 ).distinct().withColumn(\"natural_disaster_key\",fn.monotonically_increasing_id())\n",
    "    \n",
    "    \n",
    "    lookup=(res.join(\n",
    "        filtered_byCountry_date,\n",
    "        on = [\n",
    "            \"disaster_type\",\"disaster_subtype\",\"disaster_nestedsubtype\",\"disaster_subgroup\",\"event_name\",\"ofda_response\",\"ttl_damages\",\"ttl_death\"\n",
    "        ])\n",
    "        .select(\"natural_disaster_key\",\"Country\",\"start_year\",\"start_month\",\"start_day\",\"end_year\",\"end_month\",\"end_day\")\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # dimension, lookup\n",
    "    return res,lookup\n",
    "\n",
    "dateDim = dateDimension()\n",
    "df, tmp=naturalDisasterDim(\n",
    "    dateDim,\n",
    "    countries_chosen=countries_chosen,\n",
    "    filePath=\"AssignmentData/ExternalSources/DISASTERS/1900_2021_DISASTERS.xlsx - emdat data.csv\"\n",
    ")\n",
    "\n",
    "display(df.toPandas())\n",
    "display(tmp.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41172b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countryDimension(time_df,indicators,countries_chosen,filePath):\n",
    "    max_year = time_df.select(fn.max(\"year\")).limit(1).collect()[0][0]\n",
    "    min_year = time_df.select(fn.min(\"year\")).limit(1).collect()[0][0]\n",
    "    \n",
    "    countries = (spark\n",
    "                       .read\n",
    "                       .format('csv')\n",
    "                           .option(\"inferSchema\",True)\n",
    "                           .option(\"header\",True)\n",
    "                           .load(filePath)\n",
    "                        )\n",
    "\n",
    "    indicators = (indicators\n",
    "                  .withColumn(\"country_name\",fn.lower(\"Country Name\"))\n",
    "                  .drop(\"Country Name\")\n",
    "                  .withColumn(\"age_dependency_ratio_workingage\",\n",
    "                              fn.when(fn.col(\"Age dependency ratio (% of working-age population)\")>100.00, 100.00)\n",
    "                              .otherwise(fn.col(\"Age dependency ratio (% of working-age population)\")),)\n",
    "                  .withColumn(\"labor_force_total\",\n",
    "                              fn.when(fn.col(\"Labor force, total\")>30000000,\n",
    "                                     fn.when(fn.col(\"Labor force, total\")>80000000,\"high\").otherwise(\"medium\")\n",
    "                                     ).otherwise(\"low\"))\n",
    "                  .select(\n",
    "                      fn.col(\"country_name\"),\n",
    "                      fn.col(\"Population, total\").alias(\"population_total\"),\n",
    "                      fn.col(\"Population growth (annual %)\").alias(\"population_growth\"),\n",
    "                      fn.col(\"Urban population growth (annual %)\").alias(\"urban_population_growth\"),\n",
    "                      fn.col(\"Urban population\").alias(\"urban_population\"),\n",
    "                      fn.col(\"Rural population\").alias(\"rural_population\"),\n",
    "                      fn.col(\"Unemployment, total (% of total labor force)\").alias(\"unemployment_rate\"),\n",
    "                      fn.col(\"age_dependency_ratio_workingage\"),\n",
    "                      fn.col(\"Poverty headcount ratio at national poverty line (% of population)\").alias(\"poverty_headcount_percentage\"),\n",
    "                      fn.col(\"labor_force_total\"),\n",
    "                      fn.col(\"Net migration\").alias(\"net_migration\"),\n",
    "                      fn.col(\"year\")\n",
    "                  )\n",
    "#                   .fillna(\n",
    "#                       indicators.select(fn.avg(\"Age dependency ratio (% of working-age population)\")).collect()[0][0],\n",
    "#                       subset=[\"age_dependency_ratio_workingage\"]\n",
    "#                   )\n",
    "                 )\n",
    "    tmp = (countries\n",
    "               .filter(fn.lower(fn.col(\"short name\")).isin(list(map(lambda x: x.lower(),countries_chosen))))\n",
    "               .select(\n",
    "                   fn.lower(\"Currency Unit\").alias(\"currency\"),\n",
    "                   fn.lower(\"short name\").alias(\"country_name\"),\n",
    "                   fn.col(\"region\"),\n",
    "               )\n",
    "          )\n",
    "    \n",
    "    res = (tmp.join(indicators,on=[\"country_name\"]).withColumn(\"country_key\",fn.monotonically_increasing_id()))\n",
    "    \n",
    "    lookup = (res.select(\n",
    "        \"country_name\",\n",
    "        \"year\",\n",
    "        \"country_key\"\n",
    "    ))\n",
    "\n",
    "           \n",
    "    return res.drop(\"year\"), lookup\n",
    "               \n",
    "dateDim = dateDimension()\n",
    "df,tmp = countryDimension(  \n",
    "    dateDim,\n",
    "    filterdCountryDf,\n",
    "    countries_chosen=countries_chosen,\n",
    "    filePath=\"AssignmentData/HNP_StatsCountry.csv\")\n",
    "\n",
    "display(df.toPandas())\n",
    "display(tmp.toPandas())\n",
    "\n",
    "summary_df(filterdCountryDf,\"Age dependency ratio (% of working-age population)\",bns=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f7d4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def educationDimension(time_df,indicators,countries_chosen,filePath):\n",
    "    #NOT SURE WHAT THIS DOES, PROBABLY CAN REMOVE\n",
    "    max_year = time_df.select(fn.max(\"year\")).limit(1).collect()[0][0]\n",
    "    min_year = time_df.select(fn.min(\"year\")).limit(1).collect()[0][0]\n",
    "    \n",
    "    #Read the file\n",
    "    countries = (spark\n",
    "                       .read\n",
    "                       .format('csv')\n",
    "                           .option(\"inferSchema\",True)\n",
    "                           .option(\"header\",True)\n",
    "                           .load(filePath)\n",
    "                        )\n",
    "    #Get the indicators for this dimension\n",
    "    #In this case:\n",
    "    \"\"\"\n",
    "        \"Primary completion rate, total (% of relevant age group)\",\n",
    "        \"School enrollment, primary (% net)\",\n",
    "        \"School enrollment, secondary (% net)\",\n",
    "        \"School enrollment, tertiary (% gross)\",\n",
    "                    \n",
    "                    \n",
    "        Bottom three suck (100+ zeros) or doesnt exist so not added\n",
    "        \"Literacy rate, adult total (% of people ages 15 and above)\",\n",
    "        \"Literacy rate, youth total (% of people ages 15-24)\"\n",
    "         Government expenditure on education, total (% of GDP)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    indicators = (indicators\n",
    "                  .withColumn(\"country_name\",fn.lower(\"Country Name\"))\n",
    "                  .drop(\"Country Name\")\n",
    "                  #Preprocess the columns that have bad data\n",
    "                  .withColumn(\"primary_completion_rate\",\n",
    "                              fn.when(fn.col(\"Primary completion rate, total (% of relevant age group)\")>100.00,100.00)\n",
    "                              .otherwise(fn.col(\"Primary completion rate, total (% of relevant age group)\")),)\n",
    "                  .select(\n",
    "                      #Add the actual data to the table\n",
    "                      fn.col(\"country_name\"),\n",
    "                      fn.col(\"primary_completion_rate\"),\n",
    "                      fn.col(\"School enrollment, primary (% net)\").alias(\"school_enrollment_primary_%_net\"),\n",
    "                      fn.col(\"School enrollment, secondary (% net)\").alias(\"school_enrollment_secondary_%_net\"),\n",
    "                      fn.col(\"School enrollment, tertiary (% gross)\").alias(\"school_enrollment_tertiary_%_gross\"),\n",
    "                      \n",
    "                      fn.col(\"year\")\n",
    "                  )\n",
    "                 )\n",
    "    #Select the countries we care about\n",
    "    tmp = (countries\n",
    "           .filter(fn.lower(fn.col(\"short name\")).isin(list(map(lambda x: x.lower(),countries_chosen))))\n",
    "            .select(\n",
    "                fn.lower(\"short name\").alias(\"country_name\"),\n",
    "               )\n",
    "    )\n",
    "    \n",
    "    #Join the indicators table and the res table to get the indicators from the countries we want\n",
    "    #Also add the key\n",
    "    res = (tmp.join(indicators,on=[\"country_name\"]).distinct().withColumn(\"education_key\",fn.monotonically_increasing_id()))\n",
    "    \n",
    "    #Set up the look up table\n",
    "    lookup = (res.select(\n",
    "        \"country_name\",\n",
    "        \"year\",\n",
    "        \"education_key\"\n",
    "    ))\n",
    "    \n",
    "    return res.drop(\"year\"), lookup\n",
    "\n",
    "#TEST CODE REMOVE LATER\n",
    "dateDim = dateDimension()\n",
    "df,tmp = educationDimension(  \n",
    "    dateDim,\n",
    "    filterdCountryDf,\n",
    "    countries_chosen=countries_chosen,\n",
    "    filePath=\"AssignmentData/HNP_StatsCountry.csv\")\n",
    "\n",
    "display(df.toPandas())\n",
    "display(tmp.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45aa004c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>percent_of_population_undernourished</th>\n",
       "      <th>life_expectancy_at_birth</th>\n",
       "      <th>mortality_rate_under_5</th>\n",
       "      <th>number_of_infant_deaths</th>\n",
       "      <th>number_of_deaths_ages_10-14</th>\n",
       "      <th>number_of_deaths_ages_15-19</th>\n",
       "      <th>number_of_deaths_ages_20-24</th>\n",
       "      <th>general_health_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canada</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>81.900000</td>\n",
       "      <td>low</td>\n",
       "      <td>1713.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>madagascar</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>62.509000</td>\n",
       "      <td>medium</td>\n",
       "      <td>35599.0</td>\n",
       "      <td>4449.0</td>\n",
       "      <td>5945.0</td>\n",
       "      <td>4791.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>china</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>76.912000</td>\n",
       "      <td>low</td>\n",
       "      <td>112595.0</td>\n",
       "      <td>16111.0</td>\n",
       "      <td>22316.0</td>\n",
       "      <td>44112.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>madagascar</td>\n",
       "      <td>33.400000</td>\n",
       "      <td>61.212000</td>\n",
       "      <td>medium</td>\n",
       "      <td>38158.0</td>\n",
       "      <td>4235.0</td>\n",
       "      <td>5205.0</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>niger</td>\n",
       "      <td>10.478095</td>\n",
       "      <td>53.411000</td>\n",
       "      <td>high</td>\n",
       "      <td>54103.0</td>\n",
       "      <td>5993.0</td>\n",
       "      <td>4032.0</td>\n",
       "      <td>4295.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>china</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>76.704000</td>\n",
       "      <td>low</td>\n",
       "      <td>123080.0</td>\n",
       "      <td>16403.0</td>\n",
       "      <td>23259.0</td>\n",
       "      <td>45199.0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>niger</td>\n",
       "      <td>10.478095</td>\n",
       "      <td>54.180000</td>\n",
       "      <td>high</td>\n",
       "      <td>53178.0</td>\n",
       "      <td>6228.0</td>\n",
       "      <td>4115.0</td>\n",
       "      <td>4409.0</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>thailand</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>73.766000</td>\n",
       "      <td>low</td>\n",
       "      <td>9848.0</td>\n",
       "      <td>2536.0</td>\n",
       "      <td>6370.0</td>\n",
       "      <td>7131.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>united states</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>77.487805</td>\n",
       "      <td>low</td>\n",
       "      <td>27770.0</td>\n",
       "      <td>3815.0</td>\n",
       "      <td>14037.0</td>\n",
       "      <td>20209.0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>mexico</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>74.966000</td>\n",
       "      <td>low</td>\n",
       "      <td>34979.0</td>\n",
       "      <td>3448.0</td>\n",
       "      <td>9465.0</td>\n",
       "      <td>13158.0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country_name  percent_of_population_undernourished  \\\n",
       "0           canada                              2.500000   \n",
       "1       madagascar                             30.400000   \n",
       "2            china                              2.500000   \n",
       "3       madagascar                             33.400000   \n",
       "4            niger                             10.478095   \n",
       "..             ...                                   ...   \n",
       "139          china                              2.500000   \n",
       "140          niger                             10.478095   \n",
       "141       thailand                             10.400000   \n",
       "142  united states                              2.500000   \n",
       "143         mexico                              4.800000   \n",
       "\n",
       "     life_expectancy_at_birth mortality_rate_under_5  number_of_infant_deaths  \\\n",
       "0                   81.900000                    low                   1713.0   \n",
       "1                   62.509000                 medium                  35599.0   \n",
       "2                   76.912000                    low                 112595.0   \n",
       "3                   61.212000                 medium                  38158.0   \n",
       "4                   53.411000                   high                  54103.0   \n",
       "..                        ...                    ...                      ...   \n",
       "139                 76.704000                    low                 123080.0   \n",
       "140                 54.180000                   high                  53178.0   \n",
       "141                 73.766000                    low                   9848.0   \n",
       "142                 77.487805                    low                  27770.0   \n",
       "143                 74.966000                    low                  34979.0   \n",
       "\n",
       "     number_of_deaths_ages_10-14  number_of_deaths_ages_15-19  \\\n",
       "0                          221.0                        712.0   \n",
       "1                         4449.0                       5945.0   \n",
       "2                        16111.0                      22316.0   \n",
       "3                         4235.0                       5205.0   \n",
       "4                         5993.0                       4032.0   \n",
       "..                           ...                          ...   \n",
       "139                      16403.0                      23259.0   \n",
       "140                       6228.0                       4115.0   \n",
       "141                       2536.0                       6370.0   \n",
       "142                       3815.0                      14037.0   \n",
       "143                       3448.0                       9465.0   \n",
       "\n",
       "     number_of_deaths_ages_20-24  general_health_key  \n",
       "0                         1392.0                   0  \n",
       "1                         4791.0                   1  \n",
       "2                        44112.0                   2  \n",
       "3                         4530.0                   3  \n",
       "4                         4295.0                   4  \n",
       "..                           ...                 ...  \n",
       "139                      45199.0                 139  \n",
       "140                       4409.0                 140  \n",
       "141                       7131.0                 141  \n",
       "142                      20209.0                 142  \n",
       "143                      13158.0                 143  \n",
       "\n",
       "[144 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>year</th>\n",
       "      <th>general_health_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canada</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>madagascar</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>china</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>madagascar</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>niger</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>china</td>\n",
       "      <td>2018</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>niger</td>\n",
       "      <td>2006</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>thailand</td>\n",
       "      <td>2009</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>united states</td>\n",
       "      <td>2005</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>mexico</td>\n",
       "      <td>2012</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country_name  year  general_health_key\n",
       "0           canada  2017                   0\n",
       "1       madagascar  2008                   1\n",
       "2            china  2019                   2\n",
       "3       madagascar  2005                   3\n",
       "4            niger  2005                   4\n",
       "..             ...   ...                 ...\n",
       "139          china  2018                 139\n",
       "140          niger  2006                 140\n",
       "141       thailand  2009                 141\n",
       "142  united states  2005                 142\n",
       "143         mexico  2012                 143\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generalHealthDimension(time_df,indicators,countries_chosen,filePath):\n",
    "    \n",
    "    #Read the file\n",
    "    countries = (spark\n",
    "                       .read\n",
    "                       .format('csv')\n",
    "                           .option(\"inferSchema\",True)\n",
    "                           .option(\"header\",True)\n",
    "                           .load(filePath)\n",
    "                        )\n",
    "    \n",
    "    # Replace null values with mean for the following columns\n",
    "    \n",
    "    list_of_attributes = [\"Prevalence of undernourishment (% of population)\", \"Life expectancy at birth, total (years)\",\n",
    "     \"Mortality rate, under-5 (per 1,000)\", \"Number of infant deaths\", \"Number of deaths ages 10-14 years\",\n",
    "    \"Number of deaths ages 15-19 years\", \"Number of deaths ages 20-24 years\"]\n",
    "\n",
    "    indicators = replaceNullWithMean(indicators, list_of_attributes)\n",
    "    \n",
    "    #Get the indicators for this dimension\n",
    "    #In this case:\n",
    "    \"\"\"\n",
    "        mortality_rate_under_5\n",
    "        life_expectancy_at_birth\n",
    "        number_of_infant_deaths\n",
    "        number_of_deaths_ages_10-14\n",
    "        number_of_deaths_ages_15-19\n",
    "        number_of_deaths_age_20_24\n",
    "        percent_of_population_undernourished\n",
    "    \"\"\"\n",
    "    \n",
    "    indicators = (indicators\n",
    "                  .withColumn(\"country_name\",fn.lower(\"Country Name\"))\n",
    "                  .drop(\"Country Name\")\n",
    "                  .withColumn(\"mortality_rate_under_5\",\n",
    "                              fn.when(fn.col(\"Mortality rate, under-5 (per 1,000)\")>50,\n",
    "                                     fn.when(fn.col(\"Mortality rate, under-5 (per 1,000)\")>100,\"high\").otherwise(\"medium\")\n",
    "                                     ).otherwise(\"low\"))\n",
    "                  .select(\n",
    "                      #Add the actual data to the table\n",
    "                      fn.col(\"country_name\"),\n",
    "                      fn.col(\"year\"),\n",
    "                      fn.col(\"Prevalence of undernourishment (% of population)\").alias(\"percent_of_population_undernourished\"),\n",
    "                      fn.col(\"Life expectancy at birth, total (years)\").alias(\"life_expectancy_at_birth\"),\n",
    "                      fn.col(\"mortality_rate_under_5\"),\n",
    "                      fn.col(\"Number of infant deaths\").alias(\"number_of_infant_deaths\"),\n",
    "                      fn.col(\"Number of deaths ages 10-14 years\").alias(\"number_of_deaths_ages_10-14\"),\n",
    "                      fn.col(\"Number of deaths ages 15-19 years\").alias(\"number_of_deaths_ages_15-19\"),\n",
    "                      fn.col(\"Number of deaths ages 20-24 years\").alias(\"number_of_deaths_ages_20-24\")\n",
    "                  )\n",
    "                 )\n",
    "    #Select the countries we care about\n",
    "    tmp = (countries\n",
    "           .filter(fn.lower(fn.col(\"short name\")).isin(list(map(lambda x: x.lower(),countries_chosen))))\n",
    "            .select(\n",
    "                fn.lower(\"short name\").alias(\"country_name\"),\n",
    "               )\n",
    "    )\n",
    "    \n",
    "    #Join the indicators table and the res table to get the indicators from the countries we want\n",
    "    #Also add the key\n",
    "    res = (tmp.join(indicators,on=[\"country_name\"]).distinct().withColumn(\"general_health_key\",fn.monotonically_increasing_id()))\n",
    "    \n",
    "    #Set up the look up table\n",
    "    lookup = (res.select(\n",
    "        \"country_name\",\n",
    "        \"year\",\n",
    "        \"general_health_key\"\n",
    "    ))\n",
    "    \n",
    "    return res.drop(\"year\"), lookup\n",
    "\n",
    "#Initializing data for this dimension\n",
    "countries_chosen = [\"United States\", \"Canada\",\"Mexico\",\"Thailand\",\"China\",\"India\",\"Niger\",\"Madagascar\",\"Guinea\"]\n",
    "df=spark.read.format(\"csv\").option(\"header\",True).option(\"inferSchema\",True).load(\"AssignmentData/HNP_StatsData.csv\")\n",
    "filterdCountryDf=filterCountryData(df,countries_chosen)\n",
    "dateDim = dateDimension()\n",
    "\n",
    "#Create the general health dimension\n",
    "df,tmp = generalHealthDimension(  \n",
    "    dateDim,\n",
    "    filterdCountryDf,\n",
    "    countries_chosen=countries_chosen,\n",
    "    filePath=\"AssignmentData/HNP_StatsCountry.csv\")\n",
    "\n",
    "display(df.toPandas())\n",
    "display(tmp.toPandas())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medicalCapabilityDimension(time_df,indicators,countries_chosen,filePath):\n",
    "    #NOT SURE WHAT THIS DOES, PROBABLY CAN REMOVE\n",
    "    max_year = time_df.select(fn.max(\"year\")).limit(1).collect()[0][0]\n",
    "    min_year = time_df.select(fn.min(\"year\")).limit(1).collect()[0][0]\n",
    "    \n",
    "    #Read the file\n",
    "    countries = (spark\n",
    "                       .read\n",
    "                       .format('csv')\n",
    "                           .option(\"inferSchema\",True)\n",
    "                           .option(\"header\",True)\n",
    "                           .load(filePath)\n",
    "                        )\n",
    "    #Get the indicators for this dimension\n",
    "    #In this case:\n",
    "    \"\"\"\n",
    "    \"Domestic general government health expenditure per capita (current US$)\", sux\n",
    "    \"Mortality rate attributed to unsafe water, unsafe sanitation and lack of hygiene (per 100,000 population)\", sux\n",
    "    \"Hospital beds (per 1,000 people)\", aight\n",
    "    \n",
    "    \"Community health workers (per 1,000 people)\", sux\n",
    "    \"People using safely managed drinking water services (% of population)\", aight\n",
    "    \"People with basic handwashing facilities including soap and water (% of population)\", aight\n",
    "    \"People using safely managed sanitation services (% of population)\" goated\n",
    "    \"Physicians (per 1,000 people)\" sux\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    indicators = (indicators\n",
    "                  .withColumn(\"country_name\",fn.lower(\"Country Name\"))\n",
    "                  .drop(\"Country Name\")\n",
    "                  #Preprocess the columns that have bad data\n",
    "                  #Use .withColumn\n",
    "                  .select(\n",
    "                      #Add the actual data to the table\n",
    "                      fn.col(\"country_name\"),\n",
    "                      fn.col(\"Hospital beds (per 1,000 people)\").alias(\"num_hospital_beds\"),\n",
    "                      fn.col(\"People with basic handwashing facilities including soap and water (% of population)\").alias(\"people_with_basic_handwashing_facilities\"),\n",
    "                      fn.col(\"People using safely managed sanitation services (% of population)\").alias(\"people_using_safely_managed_sanitation\"),\n",
    "                      \n",
    "                      fn.col(\"year\")\n",
    "                  )\n",
    "                 )\n",
    "    #Select the countries we care about\n",
    "    tmp = (countries\n",
    "           .filter(fn.lower(fn.col(\"short name\")).isin(list(map(lambda x: x.lower(),countries_chosen))))\n",
    "            .select(\n",
    "                fn.lower(\"short name\").alias(\"country_name\"),\n",
    "               )\n",
    "    )\n",
    "    \n",
    "    #Join the indicators table and the res table to get the indicators from the countries we want\n",
    "    #Also add the key\n",
    "    res = (tmp.join(indicators,on=[\"country_name\"]).withColumn(\"medical_capability_key\",fn.monotonically_increasing_id()))\n",
    "    \n",
    "    #Set up the look up table\n",
    "    lookup = (res.select(\n",
    "        \"country_name\",\n",
    "        \"year\",\n",
    "        \"medical_capability_key\"\n",
    "    ))\n",
    "    \n",
    "    return res.drop(\"year\"), lookup\n",
    "\n",
    "#TEST CODE REMOVE LATER\n",
    "dateDim = dateDimension()\n",
    "df,tmp = medicalCapabilityDimension(  \n",
    "    dateDim,\n",
    "    filterdCountryDf,\n",
    "    countries_chosen=countries_chosen,\n",
    "    filePath=\"AssignmentData/HNP_StatsCountry.csv\")\n",
    "\n",
    "display(df.toPandas())\n",
    "display(tmp.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def immunizationDimension(time_df,indicators,countries_chosen,filePath):\n",
    "    #NOT SURE WHAT THIS DOES, PROBABLY CAN REMOVE\n",
    "    max_year = time_df.select(fn.max(\"year\")).limit(1).collect()[0][0]\n",
    "    min_year = time_df.select(fn.min(\"year\")).limit(1).collect()[0][0]\n",
    "    \n",
    "    #Read the file\n",
    "    countries = (spark\n",
    "                       .read\n",
    "                       .format('csv')\n",
    "                           .option(\"inferSchema\",True)\n",
    "                           .option(\"header\",True)\n",
    "                           .load(filePath)\n",
    "                        )\n",
    "    #Get the indicators for this dimension\n",
    "    #In this case:\n",
    "    \"\"\"\n",
    "    \"Children (0-14) living with HIV\", aight\n",
    "    \"Immunization, HepB3 (% of one-year-old children)\", goated\n",
    "    \"Immunization, BCG (% of one-year-old children)\", goated\n",
    "    \"Immunization, Hib3 (% of children ages 12-23 months)\", aight\n",
    "    \"Immunization, DPT (% of children ages 12-23 months)\" goated\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    indicators = (indicators\n",
    "                  .withColumn(\"country_name\",fn.lower(\"Country Name\"))\n",
    "                  .drop(\"Country Name\")\n",
    "                  #Preprocess the columns that have bad data\n",
    "                  #Use .withColumn\n",
    "                  .select(\n",
    "                      #Add the actual data to the table\n",
    "                      fn.col(\"country_name\"),\n",
    "                      fn.col(\"Children (0-14) living with HIV\").alias(\"children_living_w_hiv\"),\n",
    "                      fn.col(\"Immunization, HepB3 (% of one-year-old children)\").alias(\"hepb3_immunization_rate\"),\n",
    "                      fn.col(\"Immunization, BCG (% of one-year-old children)\").alias(\"bcg_immunization_rate\"),\n",
    "                      fn.col(\"Immunization, Hib3 (% of children ages 12-23 months)\").alias(\"hib3_immunization_rate\"),\n",
    "                      fn.col(\"Immunization, DPT (% of children ages 12-23 months)\").alias(\"dpt_immunization_rate\"),\n",
    "                      \n",
    "                      fn.col(\"year\")\n",
    "                  )\n",
    "                 )\n",
    "    #Select the countries we care about\n",
    "    tmp = (countries\n",
    "           .filter(fn.lower(fn.col(\"short name\")).isin(list(map(lambda x: x.lower(),countries_chosen))))\n",
    "            .select(\n",
    "                fn.lower(\"short name\").alias(\"country_name\"),\n",
    "               )\n",
    "    )\n",
    "    \n",
    "    #Join the indicators table and the res table to get the indicators from the countries we want\n",
    "    #Also add the key\n",
    "    res = (tmp.join(indicators,on=[\"country_name\"]).withColumn(\"immunization_key\",fn.monotonically_increasing_id()))\n",
    "    \n",
    "    #Set up the look up table\n",
    "    lookup = (res.select(\n",
    "        \"country_name\",\n",
    "        \"year\",\n",
    "        \"immunization_key\"\n",
    "    ))\n",
    "    \n",
    "    return res.drop(\"year\"), lookup\n",
    "\n",
    "#TEST CODE REMOVE LATER\n",
    "dateDim = dateDimension()\n",
    "df,tmp = immunizationDimension(  \n",
    "    dateDim,\n",
    "    filterdCountryDf,\n",
    "    countries_chosen=countries_chosen,\n",
    "    filePath=\"AssignmentData/HNP_StatsCountry.csv\")\n",
    "\n",
    "display(df.toPandas())\n",
    "display(tmp.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b73a423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 23:03:29 WARN Utils: Your hostname, lgcypher-Inspiron-13-5378 resolves to a loopback address: 127.0.1.1; using 192.168.0.71 instead (on interface wlp1s0)\n",
      "22/03/16 23:03:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/lgcypher/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/16 23:03:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"ds_datastage\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9fd12d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAIN block\n",
    "countries_chosen = [\"United States\", \"Canada\",\"Mexico\",\"Thailand\",\"China\",\"India\",\"Niger\",\"Madagascar\",\"Guinea\"]\n",
    "\n",
    "df=spark.read.format(\"csv\").option(\"header\",True).option(\"inferSchema\",True).load(\"AssignmentData/HNP_StatsData.csv\")\n",
    "\n",
    "#filtered data\n",
    "filterdCountryDf=filterCountryData(df,countries_chosen)\n",
    "\n",
    "dateDim = dateDimension()\n",
    "generalHealthDimension, nd_lookup=generalHealthDim(\n",
    "    dateDim,\n",
    "    countries_chosen=countries_chosen,\n",
    "    filePath=\"\n",
    ")\n",
    "\n",
    "# countryDimension = \n",
    "# display(naturalDisasterDimension.toPandas())\n",
    "# display(nd_lookup.toPandas())\n",
    "display(filterdCountryDf.toPandas())\n",
    "# display(dateDim.toPandas())\n",
    "filterdCountryDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### TESTING BLOCK\n",
    "\n",
    "\n",
    "# ## LOOKUP TABLE LOGIC\n",
    "# # 2006-2010\n",
    "# tmp = dateDim.filter(fn.col(\"year\")==2006).select(fn.col(\"year\").alias(\"year_2\"))\n",
    "# dateDim_a = dateDim.alias(\"a\")\n",
    "# tmp_b = tmp.alias(\"b\")\n",
    "\n",
    "# test2 = dateDim_a.join(tmp_b.alias(\"b\"),tmp_b.year_2<dateDim_a.year)\n",
    "# test3 = dateDim_a.join(tmp_b.alias(\"b\"),2010>dateDim_a.year)\n",
    "\n",
    "# test2.show()\n",
    "# test3.show()\n",
    "\n",
    "# test3.intersect(test2).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71b342e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST FUNCTIONS\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "# df - dataframe\n",
    "# cls - columns to replace null with medians\n",
    "# returns dataframe with the corresponding columns null values as median\n",
    "def replaceNullWithMean(df, cls):\n",
    "    for column in cls:\n",
    "        mean = df.filter(fn.col(column).isNotNull()).agg(fn.mean(column).alias(\"mean\"))\n",
    "        df = df.fillna(mean.collect()[0][0], column)\n",
    "    return df\n",
    "\n",
    "# df - dataframe\n",
    "# col - column to observe\n",
    "def nullCount(df,cl):\n",
    "    non_null =(df\n",
    "     .filter(fn.col(cl).isNotNull())\n",
    "    )\n",
    "    \n",
    "    null = (df\n",
    "        .filter(fn.col(cl).isNull()))\n",
    "    \n",
    "    print(\"Number of non null values: \"+str(non_null.count()))\n",
    "    print(\"Number of null values: \"+str(null.count()))\n",
    "    \n",
    "    \n",
    "def summary_df(df,cl,bns = 10):\n",
    "    \"\"\"\n",
    "        returns null counts, basic statistics & plot of current values in a column\n",
    "        \n",
    "        df - dataframe you wish to observer these statistics\n",
    "        cl - column of which you wish to observe\n",
    "        bns - bins (number of bars) histogram will try to bucketize data in\n",
    "    \"\"\"\n",
    "    nullCount(df,cl)\n",
    "    \n",
    "#     df.groupBy(fn.col(cl)).count().orderBy(fn.asc(fn.col(cl))).show()\n",
    "#     df.groupBy(fn.col(cl)).count().orderBy(fn.desc(fn.col(cl))).show()\n",
    "    \n",
    "    tmp = df.filter(fn.col(cl).isNotNull())\n",
    "    tmp.select(cl).describe().show()\n",
    "\n",
    "    pd_data = tmp.select(fn.col(cl)).toPandas()\n",
    "    # display(pd_data)\n",
    "    plt.hist(pd_data,bins = bns)\n",
    "    plt.title(\"Histogram of \" +str(cl))\n",
    "    plt.xlabel(cl)\n",
    "    plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe summaries here: just change the middle parameter with the indicator of choice, change bns if you want\n",
    "summary_df(filterdCountryDf,\"\",bns=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterdCountryDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = 'Primary completion rate, total (% of relevant age group)'\n",
    "first = filterdCountryDf.filter(fn.col(cl).isNotNull()).groupBy(\"Country Name\").agg(fn.count(\"*\").alias(\"nonnull\"))\n",
    "second = filterdCountryDf.filter(fn.col(cl).isNull()).groupBy(\"Country Name\").agg(fn.count(\"*\").alias(\"null\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "second.join(first,[\"Country Name\"],'right').withColumn(\"ratio\",fn.col(\"nonnull\")/fn.col(\"null\")).orderBy(fn.desc(\"ratio\")).show(300,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a39be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
