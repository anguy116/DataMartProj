{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a2652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "import pyspark.sql.types\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3e4bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filters years from 2005-2020\n",
    "# 2. Unbucketize the columns\n",
    "# 3. Filters chosen countries\n",
    "def filterCountryData(df,countries_chosen):\n",
    "    \n",
    "    # range b/w 2005-2020\n",
    "    years = list(map(lambda x: str(x),list(range(2005,2021,1)))) \n",
    "    \n",
    "    cols =[\"Country Name\",\"Country Code\",\"Indicator Name\",\"Indicator Code\"]+years\n",
    "    country_2005_20 = df.select(cols)\n",
    "    \n",
    "    \n",
    "    # filters countries chosen and fills any missing year values with 0.00\n",
    "    ts = \"2020-04-01\"\n",
    "    countries_chosen_2005_20 = (country_2005_20\n",
    "                                .filter(fn.col(\"Country Name\").isin(countries_chosen)).fillna(0.00, subset=years)\n",
    "                                .withColumn(\"date\",fn.date_format(fn.lit(ts),\"yyyy-MM-dd\"))\n",
    "                               )\n",
    "    \n",
    "    #unbucketize the data\n",
    "    unpivotStr= list(map(lambda x: \" '{t}',`{t}`\".format(t=x),years))\n",
    "    sep = ','\n",
    "    unpivotExpr = \"stack(\"+str(len(years))+\", \"+sep.join(unpivotStr)+\") as (Year, Value)\"\n",
    "    columns_without_years= set(countries_chosen_2005_20.columns ) - set(years)\n",
    "    \n",
    "    res = countries_chosen_2005_20.select(\n",
    "        \"Country Name\",\n",
    "        \"Country Code\",\n",
    "        \"Indicator Name\",\n",
    "        fn.expr(unpivotExpr),\n",
    "        fn.month(\"date\").alias(\"month\"),\n",
    "        fn.dayofmonth(\"date\").alias(\"day\"),\n",
    "        fn.quarter(\"date\").alias(\"quarter\")            \n",
    "    )\n",
    "    \n",
    "    #TODO: join the dimensions to make a fact table\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "002bfeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Dimension\n",
    "def generate_dates(spark,range_list,interval=60*60*24,dt_col=\"date_time_ref\"): # TODO: attention to sparkSession\n",
    "     \"\"\"\n",
    "     Create a Spark DataFrame with a single column named dt_col and a range of date within a specified interval (start and stop included).\n",
    "     With hourly data, dates end at 23 of stop day\n",
    "\n",
    "     :param spark: SparkSession or sqlContext depending on environment (server vs local)\n",
    "     :param range_list: array of strings formatted as \"2018-01-20\" or \"2018-01-20 00:00:00\"\n",
    "     :param interval: number of seconds (frequency), output from get_freq()\n",
    "     :param dt_col: string with date column name. Date column must be TimestampType\n",
    "\n",
    "     :returns: df from range\n",
    "     \"\"\"\n",
    "     start,stop = range_list\n",
    "     temp_df = spark.createDataFrame([(start, stop)], (\"start\", \"stop\"))\n",
    "     temp_df = temp_df.select([fn.col(c).cast(\"timestamp\") for c in (\"start\", \"stop\")])\n",
    "     temp_df = temp_df.withColumn(\"stop\",fn.date_add(\"stop\",1).cast(\"timestamp\"))\n",
    "     temp_df = temp_df.select([fn.col(c).cast(\"long\") for c in (\"start\", \"stop\")])\n",
    "     start, stop = temp_df.first()\n",
    "     return spark.range(start,stop,interval).select(fn.col(\"id\").cast(\"timestamp\").alias(dt_col))\n",
    "\n",
    "\n",
    "def dateDimension():\n",
    "    time_rng = [\"2005-01-01\",\"2020-12-31\"]\n",
    "    year_df= generate_dates(spark,time_rng)\n",
    "    tmp = (year_df\n",
    "           .withColumn(\"year\",fn.year(\"date_time_ref\"))\n",
    "           .withColumn(\"month\",fn.month(\"date_time_ref\"))\n",
    "           .withColumn(\"day\",fn.dayofmonth(\"date_time_ref\"))\n",
    "           .withColumn(\"quarter\",fn.quarter(\"date_time_ref\"))\n",
    "           .withColumn(\"decade\",\n",
    "                          fn.when(fn.col(\"year\") % 10 >=5,fn.col(\"year\")-fn.col(\"year\")%10+10)\n",
    "                              .otherwise(fn.col(\"year\")- fn.col(\"year\") % 10))\n",
    "           .withColumn(\"year_code\",fn.monotonically_increasing_id())\n",
    "\n",
    "          )\n",
    "    date_dim = (tmp\n",
    "                   .select(tmp.year_code,*set(tmp.columns)-set([\"year_code\"]))\n",
    "               )\n",
    "    \n",
    "    return date_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb726a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naturalDisasterDim(df,filePath,countries_chosen):\n",
    "    \"\"\"\n",
    "        creates natural disaster dimension + look up table\n",
    "    \n",
    "        df - date dataframe\n",
    "        filePath - filePath to natural disaster csv\n",
    "        countries_chosen - list of strings of countries to work on\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # reads csv\n",
    "    natural_disaster_df = (spark\n",
    "                       .read\n",
    "                       .format('csv')\n",
    "                       .option(\"inferSchema\",True)\n",
    "                       .option(\"header\",True)\n",
    "                       .load(filePath))\n",
    "    \n",
    "    \n",
    "    # reconfigures column names \n",
    "    tmp_nd = (natural_disaster_df\n",
    "                  # replaces United States of America -> united states\n",
    "                  .withColumn(\"Country\",fn.when(fn.lower(fn.col(\"Country\")).contains(\"united states\"),\"united states\").otherwise(fn.lower(fn.col(\"Country\"))))\n",
    "                  .withColumn(\"start_month\",fn.col(\"Start Month\"))\n",
    "                  .withColumn(\"start_year\",fn.col(\"Start Year\"))\n",
    "                  .withColumn(\"start_day\",fn.col(\"Start Day\"))\n",
    "                  .withColumn(\"end_month\",fn.col(\"End Month\"))\n",
    "                  .withColumn(\"end_year\",fn.col(\"End Year\"))\n",
    "                  .withColumn(\"end_day\",fn.col(\"End Day\"))\n",
    "                  .drop(\"year\")\n",
    "             )\n",
    "\n",
    "    # join on start year\n",
    "    nd_j_on_date = df.join(tmp_nd,tmp_nd.start_year==df.year).select(*tmp_nd.columns)\n",
    "    \n",
    "    \n",
    "    # filter countries chosen\n",
    "    tmp = (nd_j_on_date\n",
    "           .filter(fn.col(\"Country\").isin(list(map(lambda x: x.lower(),countries_chosen))))\n",
    "           .withColumn(\"NaturalDisasterKey\",fn.monotonically_increasing_id())\n",
    "          )\n",
    "    \n",
    "    \n",
    "    lookup = (tmp\n",
    "              .select(\n",
    "                  \"NaturalDisasterKey\",\n",
    "                  \"Country\",\n",
    "                  \"start_year\",\n",
    "                  \"start_month\",\n",
    "                  \"start_day\",\n",
    "                  \"end_year\",\n",
    "                  \"end_month\",\n",
    "                  \"end_day\"\n",
    "              ))\n",
    "    \n",
    "    natural_disaster_dimension = (tmp\n",
    "                                  .select(fn.col(\"NaturalDisasterKey\"),\n",
    "                                          fn.col(\"country\").alias(\"region\"),\n",
    "                                          fn.col(\"Disaster Type\").alias(\"disaster_type\"),\n",
    "                                          fn.col(\"disaster subtype\").alias(\"diaster_subtype\"),\n",
    "                                          fn.col(\"disaster subsubtype\").alias(\"disaster_nestedsubtype\"),\n",
    "                                           fn.col(\"disaster subgroup\").alias(\"disaster_subgroup\"),\n",
    "                                           fn.col(\"event name\").alias(\"event_name\"),\n",
    "                                           fn.col(\"no injured\").alias(\"ttl_injured\"),\n",
    "                                          fn.col(\"total deaths\").alias(\"ttl_death\"),\n",
    "                                   fn.col(\"no affected\").alias(\"ttl_affected\"),\n",
    "                                   fn.col(\"Total Damages ('000 US$)\").alias(\"ttl_damaged_usd_thousands\"),\n",
    "                                   fn.col(\"ofda response\").alias(\"ofda_response\"))\n",
    "                                 )\n",
    "    \n",
    "    return natural_disaster_dimension,lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41172b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def countryDimension(df,countries_chosen):\n",
    "    \n",
    "#     tmp = (df\n",
    "#                .filter(fn.lower(fn.col(\"Country\")).isin(list(map(lambda x: x.lower(),countries_chosen))))\n",
    "#                .withColumn(\"\")\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ds_datastage\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7d9fd12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaturalDisasterKey</th>\n",
       "      <th>region</th>\n",
       "      <th>disaster_type</th>\n",
       "      <th>diaster_subtype</th>\n",
       "      <th>disaster_nestedsubtype</th>\n",
       "      <th>disaster_subgroup</th>\n",
       "      <th>event_name</th>\n",
       "      <th>ttl_injured</th>\n",
       "      <th>ttl_death</th>\n",
       "      <th>ttl_affected</th>\n",
       "      <th>ttl_damaged_usd_thousands</th>\n",
       "      <th>ofda_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>japan</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>None</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>None</td>\n",
       "      <td>735.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>japan</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>None</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>None</td>\n",
       "      <td>735.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>japan</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>None</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>None</td>\n",
       "      <td>735.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>japan</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>None</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>None</td>\n",
       "      <td>735.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>japan</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>None</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>None</td>\n",
       "      <td>735.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295114</th>\n",
       "      <td>8590004000</td>\n",
       "      <td>united states</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>Forest fire</td>\n",
       "      <td>None</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>August Complex fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295115</th>\n",
       "      <td>8590004001</td>\n",
       "      <td>united states</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>Forest fire</td>\n",
       "      <td>None</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>August Complex fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295116</th>\n",
       "      <td>8590004002</td>\n",
       "      <td>united states</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>Forest fire</td>\n",
       "      <td>None</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>August Complex fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295117</th>\n",
       "      <td>8590004003</td>\n",
       "      <td>united states</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>Forest fire</td>\n",
       "      <td>None</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>August Complex fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295118</th>\n",
       "      <td>8590004004</td>\n",
       "      <td>united states</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>Forest fire</td>\n",
       "      <td>None</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>August Complex fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295119 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NaturalDisasterKey         region disaster_type  diaster_subtype  \\\n",
       "0                        0          japan    Earthquake  Ground movement   \n",
       "1                        1          japan    Earthquake  Ground movement   \n",
       "2                        2          japan    Earthquake  Ground movement   \n",
       "3                        3          japan    Earthquake  Ground movement   \n",
       "4                        4          japan    Earthquake  Ground movement   \n",
       "...                    ...            ...           ...              ...   \n",
       "295114          8590004000  united states      Wildfire      Forest fire   \n",
       "295115          8590004001  united states      Wildfire      Forest fire   \n",
       "295116          8590004002  united states      Wildfire      Forest fire   \n",
       "295117          8590004003  united states      Wildfire      Forest fire   \n",
       "295118          8590004004  united states      Wildfire      Forest fire   \n",
       "\n",
       "       disaster_nestedsubtype disaster_subgroup           event_name  \\\n",
       "0                        None       Geophysical                 None   \n",
       "1                        None       Geophysical                 None   \n",
       "2                        None       Geophysical                 None   \n",
       "3                        None       Geophysical                 None   \n",
       "4                        None       Geophysical                 None   \n",
       "...                       ...               ...                  ...   \n",
       "295114                   None    Climatological  August Complex fire   \n",
       "295115                   None    Climatological  August Complex fire   \n",
       "295116                   None    Climatological  August Complex fire   \n",
       "295117                   None    Climatological  August Complex fire   \n",
       "295118                   None    Climatological  August Complex fire   \n",
       "\n",
       "        ttl_injured  ttl_death  ttl_affected  ttl_damaged_usd_thousands  \\\n",
       "0             735.0        1.0        2800.0                   400000.0   \n",
       "1             735.0        1.0        2800.0                   400000.0   \n",
       "2             735.0        1.0        2800.0                   400000.0   \n",
       "3             735.0        1.0        2800.0                   400000.0   \n",
       "4             735.0        1.0        2800.0                   400000.0   \n",
       "...             ...        ...           ...                        ...   \n",
       "295114          NaN       32.0           NaN                 11000000.0   \n",
       "295115          NaN       32.0           NaN                 11000000.0   \n",
       "295116          NaN       32.0           NaN                 11000000.0   \n",
       "295117          NaN       32.0           NaN                 11000000.0   \n",
       "295118          NaN       32.0           NaN                 11000000.0   \n",
       "\n",
       "       ofda_response  \n",
       "0               None  \n",
       "1               None  \n",
       "2               None  \n",
       "3               None  \n",
       "4               None  \n",
       "...              ...  \n",
       "295114          None  \n",
       "295115          None  \n",
       "295116          None  \n",
       "295117          None  \n",
       "295118          None  \n",
       "\n",
       "[295119 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaturalDisasterKey</th>\n",
       "      <th>Country</th>\n",
       "      <th>start_year</th>\n",
       "      <th>start_month</th>\n",
       "      <th>start_day</th>\n",
       "      <th>end_year</th>\n",
       "      <th>end_month</th>\n",
       "      <th>end_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>japan</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>japan</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>japan</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>japan</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>japan</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295114</th>\n",
       "      <td>8590004000</td>\n",
       "      <td>united states</td>\n",
       "      <td>2020</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295115</th>\n",
       "      <td>8590004001</td>\n",
       "      <td>united states</td>\n",
       "      <td>2020</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295116</th>\n",
       "      <td>8590004002</td>\n",
       "      <td>united states</td>\n",
       "      <td>2020</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295117</th>\n",
       "      <td>8590004003</td>\n",
       "      <td>united states</td>\n",
       "      <td>2020</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295118</th>\n",
       "      <td>8590004004</td>\n",
       "      <td>united states</td>\n",
       "      <td>2020</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295119 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NaturalDisasterKey        Country  start_year  start_month  start_day  \\\n",
       "0                        0          japan        2005          3.0       20.0   \n",
       "1                        1          japan        2005          3.0       20.0   \n",
       "2                        2          japan        2005          3.0       20.0   \n",
       "3                        3          japan        2005          3.0       20.0   \n",
       "4                        4          japan        2005          3.0       20.0   \n",
       "...                    ...            ...         ...          ...        ...   \n",
       "295114          8590004000  united states        2020          8.0       16.0   \n",
       "295115          8590004001  united states        2020          8.0       16.0   \n",
       "295116          8590004002  united states        2020          8.0       16.0   \n",
       "295117          8590004003  united states        2020          8.0       16.0   \n",
       "295118          8590004004  united states        2020          8.0       16.0   \n",
       "\n",
       "        end_year  end_month  end_day  \n",
       "0           2005        3.0     20.0  \n",
       "1           2005        3.0     20.0  \n",
       "2           2005        3.0     20.0  \n",
       "3           2005        3.0     20.0  \n",
       "4           2005        3.0     20.0  \n",
       "...          ...        ...      ...  \n",
       "295114      2020       10.0      1.0  \n",
       "295115      2020       10.0      1.0  \n",
       "295116      2020       10.0      1.0  \n",
       "295117      2020       10.0      1.0  \n",
       "295118      2020       10.0      1.0  \n",
       "\n",
       "[295119 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MAIN block\n",
    "countries_chosen = [\"United States\", \"Canada\",\"Mexico\",\"Thailand\",\"Finland\",\"Nigeria\",\"Somalia\",\"Norway\",\"Japan\"]\n",
    "\n",
    "\n",
    "\n",
    "df=spark.read.format(\"csv\").option(\"header\",True).option(\"inferSchema\",True).load(\"AssignmentData/HNP_StatsData.csv\")\n",
    "\n",
    "#filtered data\n",
    "# filterdCountryDf=filterCountryData(df,countries_chosen)\n",
    "dateDim = dateDimension()\n",
    "naturalDisasterDimension, nd_lookup=naturalDisasterDim(\n",
    "    dateDim,\n",
    "    countries_chosen=countries_chosen,\n",
    "    filePath=\"AssignmentData/ExternalSources/DISASTERS/1900_2021_DISASTERS.xlsx - emdat data.csv\"\n",
    ")\n",
    "# countryDimension = \n",
    "\n",
    "# display(filterdCountryDf.toPandas())\n",
    "# display(dateDim.toPandas())\n",
    "display(naturalDisasterDimension.toPandas())\n",
    "display(nd_lookup.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aa8c6255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+------+------+\n",
      "|   year_code|year|decade|year_2|\n",
      "+------------+----+------+------+\n",
      "| 17179869184|2007|  2010|  2006|\n",
      "| 25769803776|2008|  2010|  2006|\n",
      "| 34359738368|2009|  2010|  2006|\n",
      "| 42949672960|2010|  2010|  2006|\n",
      "| 51539607552|2011|  2010|  2006|\n",
      "| 60129542144|2012|  2010|  2006|\n",
      "| 68719476736|2013|  2010|  2006|\n",
      "| 77309411328|2014|  2010|  2006|\n",
      "| 85899345920|2015|  2020|  2006|\n",
      "| 94489280512|2016|  2020|  2006|\n",
      "|103079215104|2017|  2020|  2006|\n",
      "|111669149696|2018|  2020|  2006|\n",
      "|120259084288|2019|  2020|  2006|\n",
      "|128849018880|2020|  2020|  2006|\n",
      "+------------+----+------+------+\n",
      "\n",
      "+-----------+----+------+------+\n",
      "|  year_code|year|decade|year_2|\n",
      "+-----------+----+------+------+\n",
      "|          0|2005|  2010|  2006|\n",
      "| 8589934592|2006|  2010|  2006|\n",
      "|17179869184|2007|  2010|  2006|\n",
      "|25769803776|2008|  2010|  2006|\n",
      "|34359738368|2009|  2010|  2006|\n",
      "+-----------+----+------+------+\n",
      "\n",
      "+-----------+----+------+------+\n",
      "|  year_code|year|decade|year_2|\n",
      "+-----------+----+------+------+\n",
      "|34359738368|2009|  2010|  2006|\n",
      "|25769803776|2008|  2010|  2006|\n",
      "|17179869184|2007|  2010|  2006|\n",
      "+-----------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### TESTING BLOCK\n",
    "\n",
    "\n",
    "## LOOKUP TABLE LOGIC\n",
    "# 2006-2010\n",
    "tmp = dateDim.filter(fn.col(\"year\")==2006).select(fn.col(\"year\").alias(\"year_2\"))\n",
    "dateDim_a = dateDim.alias(\"a\")\n",
    "tmp_b = tmp.alias(\"b\")\n",
    "\n",
    "test2 = dateDim_a.join(tmp_b.alias(\"b\"),tmp_b.year_2<dateDim_a.year)\n",
    "test3 = dateDim_a.join(tmp_b.alias(\"b\"),2010>dateDim_a.year)\n",
    "\n",
    "test2.show()\n",
    "test3.show()\n",
    "\n",
    "test3.intersect(test2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b342e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST FUNCTION\n",
    "# df - dataframe\n",
    "# col - column to observe\n",
    "def nullCount(df,cl):\n",
    "    non_null =(df\n",
    "     .filter(fn.col(cl).isNotNull())\n",
    "     .select(df.ttl_damaged_usd_thousands)\n",
    "     .groupBy(df.ttl_damaged_usd_thousands)\n",
    "     .count()\n",
    "     .sort(naturalDisasterDimension.ttl_damaged_usd_thousands.asc())\n",
    "    )\n",
    "    \n",
    "    print(\"Number of non null values: \"+non_null.count())\n",
    "    null = (naturalDisasterDimension\n",
    "        .filter(naturalDisasterDimension.ttl_damaged_usd_thousands.isNull())\n",
    "        .groupBy(naturalDisasterDimension.ttl_damaged_usd_thousands)\n",
    "        .count().alias(\"null count\")\n",
    "        .show()\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
